{"metadata":{"role":"collectionGroup","title":"Metal Effects","modules":[{"name":"AudioUI"}],"roleHeading":"API Collection"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/audioui\/metaleffects"]}],"hierarchy":{"paths":[["doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI"],["doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI","doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/AudioUIMetalFX"]]},"identifier":{"url":"doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/MetalEffects","interfaceLanguage":"swift"},"seeAlsoSections":[{"title":"Performance & Platform","generated":true,"identifiers":["doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/PerformanceOptimization","doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/RealTimeAudio","doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/CrossPlatformConsiderations"],"anchor":"Performance--Platform"}],"primaryContentSections":[{"kind":"content","content":[{"text":"Overview","type":"heading","anchor":"Overview","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"AudioUIMetalFX provides GPU-accelerated visual effects that respond to audio in real-time. These effects use Appleâ€™s Metal framework to achieve smooth 60fps+ rendering while maintaining low CPU usage, essential for professional audio applications."}]},{"text":"Core Metal Effects","type":"heading","anchor":"Core-Metal-Effects","level":2},{"text":"Spectrum Analyzer","type":"heading","anchor":"Spectrum-Analyzer","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Real-time frequency domain visualization with customizable appearance:"}]},{"code":["import AudioUI","import AudioUIMetalFX","","struct SpectrumAnalyzer: View {","    @StateObject private var audioEngine = AudioEngine()","    ","    var body: some View {","        SpectrumVisualizer(","            fftData: audioEngine.fftBuffer,","            barCount: 64,","            style: .bars","        )","        .frame(height: 200)","        .onAppear {","            audioEngine.startAnalysis()","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"text":"Configuration Options:","type":"text"}]}]},{"code":["SpectrumVisualizer(","    fftData: audioEngine.fftBuffer,","    barCount: 32,                    \/\/ Number of frequency bars","    style: .bars,                    \/\/ .bars, .line, .filled","    colorScheme: .spectrum,          \/\/ Color mapping","    smoothing: 0.8,                  \/\/ Temporal smoothing","    logScale: true,                  \/\/ Logarithmic frequency scale","    peakHold: true,                  \/\/ Peak indicators","    falloffRate: 0.95               \/\/ Peak decay rate",")"],"type":"codeListing","syntax":"swift"},{"text":"Waveform Display","type":"heading","anchor":"Waveform-Display","level":3},{"type":"paragraph","inlineContent":[{"text":"Real-time time domain visualization:","type":"text"}]},{"code":["struct WaveformDisplay: View {","    @StateObject private var audioEngine = AudioEngine()","    ","    var body: some View {","        WaveformVisualizer(","            audioBuffer: audioEngine.timeBuffer,","            style: .oscilloscope","        )","        .frame(height: 150)","        .background(Color.black)","    }","}"],"type":"codeListing","syntax":"swift"},{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Waveform Styles:"}]}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"code":".oscilloscope","type":"codeVoice"},{"type":"text","text":": Classic oscilloscope display"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"codeVoice","code":".filled"},{"type":"text","text":": Filled waveform with gradient"}]}]},{"content":[{"inlineContent":[{"type":"codeVoice","code":".mirrored"},{"type":"text","text":": Symmetric waveform display"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"codeVoice","code":".stereo"},{"text":": Dual-channel visualization","type":"text"}],"type":"paragraph"}]}]},{"text":"Level Meter Array","type":"heading","anchor":"Level-Meter-Array","level":3},{"type":"paragraph","inlineContent":[{"text":"GPU-accelerated multi-channel level display:","type":"text"}]},{"code":["struct MultiChannelMeters: View {","    let channelCount: Int = 32","    @StateObject private var mixer = AudioMixer()","    ","    var body: some View {","        MetalLevelMeterArray(","            levels: mixer.channelLevels,","            peaks: mixer.channelPeaks,","            orientation: .vertical","        )","        .frame(width: 400, height: 200)","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Particle Effects","type":"heading","anchor":"Particle-Effects","level":3},{"type":"paragraph","inlineContent":[{"text":"Audio-reactive particle systems:","type":"text"}]},{"code":["struct AudioParticles: View {","    @StateObject private var audioEngine = AudioEngine()","    ","    var body: some View {","        ParticleSystemView(","            intensity: audioEngine.overallLevel,","            frequency: audioEngine.dominantFrequency,","            style: .fireflies","        )","        .frame(maxWidth: .infinity, maxHeight: .infinity)","        .background(Color.black)","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Advanced Effects","type":"heading","anchor":"Advanced-Effects","level":2},{"text":"Spectrogram","type":"heading","anchor":"Spectrogram","level":3},{"type":"paragraph","inlineContent":[{"text":"Time-frequency analysis with scrolling display:","type":"text"}]},{"code":["struct SpectrogramView: View {","    @StateObject private var audioEngine = AudioEngine()","    ","    var body: some View {","        MetalSpectrogram(","            fftData: audioEngine.fftBuffer,","            bufferSize: 1024,","            colorMap: .jet,","            scrollDirection: .leftToRight","        )","        .frame(width: 400, height: 300)","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"3D Spectrum","type":"heading","anchor":"3D-Spectrum","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Three-dimensional frequency visualization:"}]},{"code":["struct Spectrum3D: View {","    @StateObject private var audioEngine = AudioEngine()","    @State private var rotationAngle: Float = 0","    ","    var body: some View {","        Metal3DSpectrum(","            fftData: audioEngine.fftBuffer,","            rotation: rotationAngle,","            perspective: 0.5,","            depth: 2.0","        )","        .frame(width: 300, height: 300)","        .gesture(","            DragGesture()","                .onChanged { value in","                    rotationAngle = Float(value.translation.x * 0.01)","                }","        )","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Vectorscope","type":"heading","anchor":"Vectorscope","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Stereo field visualization:"}]},{"code":["struct Vectorscope: View {","    @StateObject private var audioEngine = AudioEngine()","    ","    var body: some View {","        MetalVectorscope(","            leftChannel: audioEngine.leftBuffer,","            rightChannel: audioEngine.rightBuffer,","            persistence: 0.9,","            dotSize: 2.0","        )","        .frame(width: 200, height: 200)","        .clipShape(Circle())","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Custom Metal Effects","type":"heading","anchor":"Custom-Metal-Effects","level":2},{"text":"Creating Custom Shaders","type":"heading","anchor":"Creating-Custom-Shaders","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Build your own audio-reactive effects:"}]},{"code":["struct CustomAudioVisualizer: View {","    @StateObject private var audioEngine = AudioEngine()","    ","    var body: some View {","        MetalView(","            shader: \"custom_audio_shader\",","            uniforms: [","                \"time\": CACurrentMediaTime(),","                \"audioLevel\": audioEngine.overallLevel,","                \"bassLevel\": audioEngine.bassLevel,","                \"midLevel\": audioEngine.midLevel,","                \"trebleLevel\": audioEngine.trebleLevel","            ]","        )","        .frame(width: 300, height: 300)","    }","}"],"type":"codeListing","syntax":"swift"},{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Custom Metal Shader Example:"}],"type":"strong"}]},{"code":["#include <metal_stdlib>","using namespace metal;","","struct VertexOut {","    float4 position [[position]];","    float2 texCoord;","};","","fragment float4 custom_audio_shader(","    VertexOut in [[stage_in]],","    constant float &time [[buffer(0)]],","    constant float &audioLevel [[buffer(1)]],","    constant float &bassLevel [[buffer(2)]],","    constant float &midLevel [[buffer(3)]],","    constant float &trebleLevel [[buffer(4)]]",") {","    float2 uv = in.texCoord;","    ","    \/\/ Create audio-reactive waves","    float wave1 = sin(uv.x * 10.0 + time * 2.0) * audioLevel;","    float wave2 = sin(uv.y * 8.0 + time * 1.5) * bassLevel;","    ","    \/\/ Combine frequency bands","    float3 color = float3(","        trebleLevel * (0.5 + 0.5 * sin(uv.x * 20.0 + time)),","        midLevel * (0.5 + 0.5 * sin(uv.y * 15.0 + time * 0.8)),","        bassLevel * (0.5 + 0.5 * sin((uv.x + uv.y) * 10.0 + time * 0.6))","    );","    ","    \/\/ Apply wave distortion","    color *= (1.0 + wave1 + wave2) * 0.5;","    ","    return float4(color, 1.0);","}"],"type":"codeListing","syntax":"metal"},{"text":"Shader Uniforms","type":"heading","anchor":"Shader-Uniforms","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Pass real-time audio data to Metal shaders:"}]},{"code":["class AudioToShaderBridge: ObservableObject {","    @Published var uniforms: [String: Float] = [:]","    private var audioEngine: AudioEngine","    ","    init(audioEngine: AudioEngine) {","        self.audioEngine = audioEngine","        startUpdating()","    }","    ","    private func startUpdating() {","        Timer.scheduledTimer(withTimeInterval: 1\/60) { _ in","            self.updateUniforms()","        }","    }","    ","    private func updateUniforms() {","        uniforms = [","            \"time\": Float(CACurrentMediaTime()),","            \"overallLevel\": audioEngine.overallLevel,","            \"bassLevel\": audioEngine.bassLevel,","            \"midLevel\": audioEngine.midLevel,","            \"trebleLevel\": audioEngine.trebleLevel,","            \"kick\": audioEngine.kickLevel,","            \"snare\": audioEngine.snareLevel,","            \"hihat\": audioEngine.hihatLevel","        ]","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Performance Optimization","type":"heading","anchor":"Performance-Optimization","level":2},{"text":"GPU Memory Management","type":"heading","anchor":"GPU-Memory-Management","level":3},{"type":"paragraph","inlineContent":[{"text":"Efficient use of Metal resources:","type":"text"}]},{"code":["class MetalEffectManager {","    private var device: MTLDevice","    private var commandQueue: MTLCommandQueue","    private var textureCache: [String: MTLTexture] = [:]","    ","    init() {","        guard let device = MTLCreateSystemDefaultDevice() else {","            fatalError(\"Metal not supported\")","        }","        self.device = device","        self.commandQueue = device.makeCommandQueue()!","    }","    ","    func cachedTexture(for key: String, size: CGSize) -> MTLTexture {","        if let cached = textureCache[key] {","            return cached","        }","        ","        let descriptor = MTLTextureDescriptor.texture2DDescriptor(","            pixelFormat: .rgba8Unorm,","            width: Int(size.width),","            height: Int(size.height),","            mipmapped: false","        )","        descriptor.usage = [.shaderRead, .renderTarget]","        ","        let texture = device.makeTexture(descriptor: descriptor)!","        textureCache[key] = texture","        return texture","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Render Pipeline Optimization","type":"heading","anchor":"Render-Pipeline-Optimization","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Reduce GPU overhead with efficient pipelines:"}]},{"code":["class OptimizedAudioVisualizer {","    private var renderPipelineState: MTLRenderPipelineState?","    private var vertexBuffer: MTLBuffer?","    ","    func setupOptimizedPipeline() {","        \/\/ Create vertex buffer once","        let vertices: [Float] = [","            -1, -1, 0, 1,  \/\/ Bottom left","             1, -1, 1, 1,  \/\/ Bottom right","            -1,  1, 0, 0,  \/\/ Top left","             1,  1, 1, 0   \/\/ Top right","        ]","        ","        vertexBuffer = device.makeBuffer(","            bytes: vertices,","            length: vertices.count * MemoryLayout<Float>.size,","            options: []","        )","        ","        \/\/ Setup render pipeline","        let descriptor = MTLRenderPipelineDescriptor()","        descriptor.vertexFunction = library.makeFunction(name: \"vertex_main\")","        descriptor.fragmentFunction = library.makeFunction(name: \"fragment_main\")","        descriptor.colorAttachments[0].pixelFormat = .bgra8Unorm","        ","        renderPipelineState = try! device.makeRenderPipelineState(descriptor: descriptor)","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Integration Patterns","type":"heading","anchor":"Integration-Patterns","level":2},{"text":"Combining with AudioUI Components","type":"heading","anchor":"Combining-with-AudioUI-Components","level":3},{"type":"paragraph","inlineContent":[{"text":"Integrate Metal effects with standard AudioUI components:","type":"text"}]},{"code":["struct ProfessionalAnalyzer: View {","    @StateObject private var audioEngine = AudioEngine()","    @State private var selectedBand: Int = 0","    ","    var body: some View {","        VStack {","            \/\/ Spectrum analyzer with Metal rendering","            SpectrumVisualizer(","                fftData: audioEngine.fftBuffer,","                selectedBand: selectedBand","            )","            .frame(height: 200)","            ","            \/\/ AudioUI controls below","            HStack {","                ForEach(0..<8) { band in","                    VStack {","                        InsetNeumorphicKnob(","                            value: $audioEngine.bandGains[band],","                            label: \"\\(bandFrequencies[band])Hz\"","                        )","                        .frame(width: 40, height: 40)","                        .highlighted(selectedBand == band)","                        .onTapGesture {","                            selectedBand = band","                        }","                    }","                }","            }","        }","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Real-Time Response","type":"heading","anchor":"Real-Time-Response","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Ensure effects respond immediately to audio changes:"}]},{"code":["class RealTimeEffectController: ObservableObject {","    @Published var effectIntensity: Float = 0","    private var audioEngine: AudioEngine","    private var displayLink: CADisplayLink?","    ","    init(audioEngine: AudioEngine) {","        self.audioEngine = audioEngine","        startDisplayLink()","    }","    ","    private func startDisplayLink() {","        displayLink = CADisplayLink(target: self, selector: #selector(update))","        displayLink?.add(to: .main, forMode: .common)","    }","    ","    @objc private func update() {","        \/\/ Update at screen refresh rate","        let newIntensity = audioEngine.calculateEffectIntensity()","        ","        \/\/ Smooth the value to prevent jitter","        effectIntensity = effectIntensity * 0.9 + newIntensity * 0.1","    }","}"],"type":"codeListing","syntax":"swift"},{"text":"Accessibility Considerations","type":"heading","anchor":"Accessibility-Considerations","level":2},{"text":"Alternative Representations","type":"heading","anchor":"Alternative-Representations","level":3},{"type":"paragraph","inlineContent":[{"type":"text","text":"Provide non-visual alternatives for audio information:"}]},{"code":["struct AccessibleSpectrumView: View {","    @StateObject private var audioEngine = AudioEngine()","    @Environment(\\.accessibilityReduceMotion) var reduceMotion","    ","    var body: some View {","        Group {","            if reduceMotion {","                \/\/ Static representation","                HStack {","                    ForEach(audioEngine.frequencyBands.indices, id: \\.self) { index in","                        Rectangle()","                            .fill(Color.blue)","                            .frame(","                                width: 20,","                                height: CGFloat(audioEngine.frequencyBands[index]) * 100","                            )","                    }","                }","            } else {","                \/\/ Full Metal effects","                SpectrumVisualizer(fftData: audioEngine.fftBuffer)","            }","        }","        .accessibilityElement(children: .ignore)","        .accessibilityLabel(\"Audio spectrum\")","        .accessibilityValue(audioEngine.accessibilityDescription)","    }","}"],"type":"codeListing","syntax":"swift"},{"type":"paragraph","inlineContent":[{"text":"Metal effects in AudioUI provide the visual polish and real-time responsiveness that distinguish professional audio applications from basic tools, while maintaining the performance required for professional audio work.","type":"text"}]}]}],"kind":"article","sections":[],"schemaVersion":{"minor":3,"major":0,"patch":0},"abstract":[{"text":"Leverage GPU acceleration to create stunning real-time visual effects for advanced audio applications using AudioUIâ€™s Metal-powered rendering system.","type":"text"}],"topicSections":[{"title":"Core Effects","identifiers":["doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/SpectrumVisualizer"],"anchor":"Core-Effects"}],"references":{"doc://audiouiswift.AudioUI/documentation/AudioUI/RealTimeAudio":{"identifier":"doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/RealTimeAudio","abstract":[{"type":"text","text":"Design AudioUI interfaces that respond seamlessly to live audio processing while maintaining professional performance standards."}],"kind":"article","url":"\/documentation\/audioui\/realtimeaudio","type":"topic","title":"Real-Time Audio","role":"collectionGroup"},"doc://audiouiswift.AudioUI/documentation/AudioUI/AudioUIMetalFX":{"title":"AudioUIMetalFX","type":"topic","kind":"article","abstract":[{"text":"GPU-accelerated visual effects and real-time graphics processing for audio interfaces.","type":"text"}],"identifier":"doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/AudioUIMetalFX","url":"\/documentation\/audioui\/audiouimetalfx","role":"collectionGroup"},"doc://audiouiswift.AudioUI/documentation/AudioUI/SpectrumVisualizer":{"fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"SpectrumVisualizer"}],"title":"SpectrumVisualizer","navigatorTitle":[{"kind":"identifier","text":"SpectrumVisualizer"}],"url":"\/documentation\/audioui\/spectrumvisualizer","kind":"symbol","type":"topic","identifier":"doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/SpectrumVisualizer","abstract":[],"role":"symbol"},"doc://audiouiswift.AudioUI/documentation/AudioUI/PerformanceOptimization":{"role":"collectionGroup","kind":"article","identifier":"doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/PerformanceOptimization","title":"Performance Optimization","type":"topic","url":"\/documentation\/audioui\/performanceoptimization","abstract":[{"text":"Advanced techniques and best practices for building high-performance audio interfaces with AudioUI that maintain smooth 60fps rendering and minimal CPU usage.","type":"text"}]},"doc://audiouiswift.AudioUI/documentation/AudioUI/CrossPlatformConsiderations":{"title":"Cross-Platform Considerations","type":"topic","role":"article","kind":"article","abstract":[{"type":"text","text":"Building audio interfaces that work seamlessly across iOS, macOS, and beyond."}],"url":"\/documentation\/audioui\/crossplatformconsiderations","identifier":"doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI\/CrossPlatformConsiderations"},"doc://audiouiswift.AudioUI/documentation/AudioUI":{"kind":"symbol","abstract":[{"type":"text","text":"The ultimate SwiftUI framework for professional audio interface development."}],"identifier":"doc:\/\/audiouiswift.AudioUI\/documentation\/AudioUI","role":"collection","type":"topic","title":"AudioUI","url":"\/documentation\/audioui"}}}